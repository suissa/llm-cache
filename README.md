# llm-cache

Camada de cache focada em conversas de LLM constru√≠da por cima do
[sdk-ioredis-fastify](https://github.com/suissa/sdk-ioredis-fastify). A biblioteca
exp√µe um Singleton que concentra toda a comunica√ß√£o com o backend Redis, o que
facilita a partilha do mesmo cliente entre diferentes partes da aplica√ß√£o sem
precisar reconfigurar conex√£o.

## Funcionalidades

- Guardar mensagens de chat em listas do Redis com TTL opcional por
  utilizador.
- Guardar o modelo LLM associado ao utilizador com TTL opcional.
- Guardar metadados ricos (resumo, token usage, prefer√™ncias, estado de ferramentas).
- Recuperar uma janela da conversa√ß√£o (com suporte a `lastN`).
- Limpar hist√≥rico e metadados de um utilizador num √∫nico `flow`.

## Instala√ß√£o

```bash
npm install sdk-ioredis-fastify
npm install llm-cache
```

> **Nota:** O SDK de Redis √© um peer obrigat√≥rio. Certifique-se de que o seu
> projecto possui acesso ao endpoint HTTP fornecido pelo fastify.

## Utiliza√ß√£o

```ts
import { LLMCache } from 'llm-cache';

const cache = LLMCache.getInstance({
  baseURL: process.env.REDIS_SDK_URL!,
  apiVersion: 'v1',
  conversationTTLSeconds: 60 * 30, // 30 minutos
});

await cache.addMessage('user-123', { role: 'user', content: 'Ol√°!' });
await cache.addMessage('user-123', { role: 'assistant', content: 'Ol√° üëã' });

const context = await cache.getConversationWindow('user-123', { lastN: 2 });

await cache.upsertConversationMetadata('user-123', {
  summary: 'Sauda√ß√£o r√°pida entre utilizador e assistente.',
  lastInteractionAt: Date.now(),
  tokenUsage: { totalTokens: 24 },
});
```

Veja `src/example.ts` para um exemplo mais completo.

## Boas pr√°ticas e poss√≠veis melhorias

- Definir `conversationTTLSeconds` e `modelTTLSeconds` para evitar acumular
  dados antigos no Redis.
- Aplicar uma pol√≠tica de trimming (`LTRIM`) quando o SDK passar a suportar
  essa opera√ß√£o para manter apenas as N mensagens mais recentes sem ter de
  apagar o hist√≥rico completo.
- Guardar dados contextuais al√©m das mensagens:
  - Resumos parciais por janela para reidratar rapidamente conversas longas;
  - Estat√≠sticas de tokens/custo para efeitos de billing e limites de uso;
  - Prefer√™ncias do utilizador (idioma, tom, persona) e estado de ferramentas
    externas necess√°rias para responder;
  - Resultados interm√©dios relevantes (links, IDs de recursos, anexos).
- Envolver chamadas de rede em camadas de retry / observabilidade (logs,
  m√©tricas) na aplica√ß√£o que consumir esta lib.
- Adicionar testes unit√°rios utilizando mocks do `sdk-ioredis-fastify` para
  validar a serializa√ß√£o das mensagens antes de publicar num registo npm.